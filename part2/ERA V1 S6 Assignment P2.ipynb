{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1685786015758}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# !pip install --upgrade torch torchvision torchinfo tqdm matplotlib"],"metadata":{"id":"2vLbBPYasp_o","executionInfo":{"status":"ok","timestamp":1685856319885,"user_tz":-330,"elapsed":20,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","executionInfo":{"status":"ok","timestamp":1685856320964,"user_tz":-330,"elapsed":1098,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchinfo import summary"],"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Device\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cpu\"\n","print(\"Device Selected:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ve2kLBJbuxyw","executionInfo":{"status":"ok","timestamp":1685856321514,"user_tz":-330,"elapsed":560,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}},"outputId":"ff486134-18d2-478a-ff6a-feeee5941b0e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Device Selected: cuda\n"]}]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685856321514,"user_tz":-330,"elapsed":16,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}},"outputId":"f781e84a-7f2e-41f2-bfd3-4895cad45ef2"},"source":["torch.manual_seed(42)\n","batch_size = 64\n","\n","kwargs = {'num_workers': 3, 'pin_memory': True} if device != 'cpu' else {}\n","\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=False, **kwargs)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","executionInfo":{"status":"ok","timestamp":1685856321514,"user_tz":-330,"elapsed":12,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}}},"source":["DROP = 0.05\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.cblock1 = nn.Sequential(\n","            nn.Conv2d(1, 8, 3, padding=1, bias=False),    # Input -  28x28x1, Output -  28x28x8, RF - 3x3\n","            nn.Dropout(DROP),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Conv2d(8, 8, 3, padding=1, bias=False),    # Input -  28x28x8, Output -  28x28x8, RF - 5x5\n","            nn.Dropout(DROP),\n","            nn.ReLU()\n","        )\n","\n","        self.tblock1 = nn.Sequential(\n","            nn.MaxPool2d(2, 2)                            # Input -  28x28x8, Output -  14x14x8, RF - 6x6\n","        )\n","\n","        self.cblock2 = nn.Sequential(\n","            nn.BatchNorm2d(8),\n","            nn.Conv2d(8, 16, 3, padding=1, bias=False),   # Input -  14x14x8, Output - 14x14x16, RF - 10x10\n","            nn.Dropout(DROP),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 16, 3, padding=1, bias=False),  # Input - 14x14x16, Output - 14x14x16, RF - 14x14\n","            nn.Dropout(DROP),\n","            nn.ReLU()\n","        )\n","\n","        self.tblock2 = nn.Sequential(\n","            nn.MaxPool2d(2, 2)                            # Input - 14x14x16, Output -   7x7x16, RF - 16x16\n","        )\n","\n","        self.cblock3 = nn.Sequential(\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 32, 3, padding=1, bias=False),  # Input -   7x7x16, Output -   7x7x32, RF - 24x24\n","            nn.Dropout(DROP),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 32, 3, padding=1, bias=False),  # Input -   7x7x32, Output -   7x7x32, RF - 32x32\n","            nn.Dropout(DROP),\n","            nn.ReLU()\n","        )\n","\n","        self.outblock = nn.Sequential(\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 32, 1, bias=False),             # Input -   7x7x32, Output -   7x7x32, RF - 32x32\n","            nn.Dropout(DROP),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 10, 1),                         # Input -   7x7x32, Output -   7x7x10, RF - 32x32\n","            nn.ReLU(),\n","            nn.AvgPool2d(7, 7),                           # Input -   7x7x10, Output -   1x1x10\n","            nn.Flatten(),\n","            nn.LogSoftmax()\n","        )\n","\n","    def forward(self, x):\n","        x = self.cblock1(x)\n","        x = self.tblock1(x)\n","        x = self.cblock2(x)\n","        x = self.tblock2(x)\n","        x = self.cblock3(x)\n","        x = self.outblock(x)\n","        return x"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685856325071,"user_tz":-330,"elapsed":3568,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}},"outputId":"f2466cf4-125b-4cf2-88c2-f402ffc82120"},"source":["model = Net().to(device)\n","summary(model, input_size=(batch_size, 1, 28, 28),\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"params_percent\"])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"]},{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %\n","============================================================================================================================================\n","Net                                      [64, 1, 28, 28]           [64, 10]                  --                             --\n","├─Sequential: 1-1                        [64, 1, 28, 28]           [64, 8, 28, 28]           --                             --\n","│    └─Conv2d: 2-1                       [64, 1, 28, 28]           [64, 8, 28, 28]           72                          0.37%\n","│    └─Dropout: 2-2                      [64, 8, 28, 28]           [64, 8, 28, 28]           --                             --\n","│    └─ReLU: 2-3                         [64, 8, 28, 28]           [64, 8, 28, 28]           --                             --\n","│    └─BatchNorm2d: 2-4                  [64, 8, 28, 28]           [64, 8, 28, 28]           16                          0.08%\n","│    └─Conv2d: 2-5                       [64, 8, 28, 28]           [64, 8, 28, 28]           576                         2.94%\n","│    └─Dropout: 2-6                      [64, 8, 28, 28]           [64, 8, 28, 28]           --                             --\n","│    └─ReLU: 2-7                         [64, 8, 28, 28]           [64, 8, 28, 28]           --                             --\n","├─Sequential: 1-2                        [64, 8, 28, 28]           [64, 8, 14, 14]           --                             --\n","│    └─MaxPool2d: 2-8                    [64, 8, 28, 28]           [64, 8, 14, 14]           --                             --\n","├─Sequential: 1-3                        [64, 8, 14, 14]           [64, 16, 14, 14]          --                             --\n","│    └─BatchNorm2d: 2-9                  [64, 8, 14, 14]           [64, 8, 14, 14]           16                          0.08%\n","│    └─Conv2d: 2-10                      [64, 8, 14, 14]           [64, 16, 14, 14]          1,152                       5.89%\n","│    └─Dropout: 2-11                     [64, 16, 14, 14]          [64, 16, 14, 14]          --                             --\n","│    └─ReLU: 2-12                        [64, 16, 14, 14]          [64, 16, 14, 14]          --                             --\n","│    └─BatchNorm2d: 2-13                 [64, 16, 14, 14]          [64, 16, 14, 14]          32                          0.16%\n","│    └─Conv2d: 2-14                      [64, 16, 14, 14]          [64, 16, 14, 14]          2,304                      11.77%\n","│    └─Dropout: 2-15                     [64, 16, 14, 14]          [64, 16, 14, 14]          --                             --\n","│    └─ReLU: 2-16                        [64, 16, 14, 14]          [64, 16, 14, 14]          --                             --\n","├─Sequential: 1-4                        [64, 16, 14, 14]          [64, 16, 7, 7]            --                             --\n","│    └─MaxPool2d: 2-17                   [64, 16, 14, 14]          [64, 16, 7, 7]            --                             --\n","├─Sequential: 1-5                        [64, 16, 7, 7]            [64, 32, 7, 7]            --                             --\n","│    └─BatchNorm2d: 2-18                 [64, 16, 7, 7]            [64, 16, 7, 7]            32                          0.16%\n","│    └─Conv2d: 2-19                      [64, 16, 7, 7]            [64, 32, 7, 7]            4,608                      23.55%\n","│    └─Dropout: 2-20                     [64, 32, 7, 7]            [64, 32, 7, 7]            --                             --\n","│    └─ReLU: 2-21                        [64, 32, 7, 7]            [64, 32, 7, 7]            --                             --\n","│    └─BatchNorm2d: 2-22                 [64, 32, 7, 7]            [64, 32, 7, 7]            64                          0.33%\n","│    └─Conv2d: 2-23                      [64, 32, 7, 7]            [64, 32, 7, 7]            9,216                      47.09%\n","│    └─Dropout: 2-24                     [64, 32, 7, 7]            [64, 32, 7, 7]            --                             --\n","│    └─ReLU: 2-25                        [64, 32, 7, 7]            [64, 32, 7, 7]            --                             --\n","├─Sequential: 1-6                        [64, 32, 7, 7]            [64, 10]                  --                             --\n","│    └─BatchNorm2d: 2-26                 [64, 32, 7, 7]            [64, 32, 7, 7]            64                          0.33%\n","│    └─Conv2d: 2-27                      [64, 32, 7, 7]            [64, 32, 7, 7]            1,024                       5.23%\n","│    └─Dropout: 2-28                     [64, 32, 7, 7]            [64, 32, 7, 7]            --                             --\n","│    └─ReLU: 2-29                        [64, 32, 7, 7]            [64, 32, 7, 7]            --                             --\n","│    └─BatchNorm2d: 2-30                 [64, 32, 7, 7]            [64, 32, 7, 7]            64                          0.33%\n","│    └─Conv2d: 2-31                      [64, 32, 7, 7]            [64, 10, 7, 7]            330                         1.69%\n","│    └─ReLU: 2-32                        [64, 10, 7, 7]            [64, 10, 7, 7]            --                             --\n","│    └─AvgPool2d: 2-33                   [64, 10, 7, 7]            [64, 10, 1, 1]            --                             --\n","│    └─Flatten: 2-34                     [64, 10, 1, 1]            [64, 10]                  --                             --\n","│    └─LogSoftmax: 2-35                  [64, 10]                  [64, 10]                  --                             --\n","============================================================================================================================================\n","Total params: 19,570\n","Trainable params: 19,570\n","Non-trainable params: 0\n","Total mult-adds (M): 123.48\n","============================================================================================================================================\n","Input size (MB): 0.20\n","Forward/backward pass size (MB): 20.72\n","Params size (MB): 0.08\n","Estimated Total Size (MB): 21.00\n","============================================================================================================================================"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","executionInfo":{"status":"ok","timestamp":1685856325071,"user_tz":-330,"elapsed":34,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}}},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'Train set: Average loss={loss.item()} batch_id={batch_idx}')\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","    return test_loss"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685856821456,"user_tz":-330,"elapsed":496408,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}},"outputId":"e2df36e3-cbd4-444b-da66-d6c92b730357"},"source":["model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True)\n","\n","for epoch in range(0, 20):\n","    print(\"Epoch {}: \".format(epoch + 1))\n","    train(model, device, train_loader, optimizer, epoch)\n","    test_loss = test(model, device, test_loader)\n","    scheduler.step(test_loss)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.3112333118915558 batch_id=937: 100%|██████████| 938/938 [00:25<00:00, 36.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0700, Accuracy: 9800/10000 (98.00%)\n","\n","Epoch 2: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.09517934918403625 batch_id=937: 100%|██████████| 938/938 [00:20<00:00, 45.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0476, Accuracy: 9856/10000 (98.56%)\n","\n","Epoch 3: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.0555470809340477 batch_id=937: 100%|██████████| 938/938 [00:20<00:00, 44.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0340, Accuracy: 9896/10000 (98.96%)\n","\n","Epoch 4: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.05665958672761917 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 42.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0375, Accuracy: 9893/10000 (98.93%)\n","\n","Epoch 5: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.005381383001804352 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 41.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0240, Accuracy: 9930/10000 (99.30%)\n","\n","Epoch 6: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.08005742728710175 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0254, Accuracy: 9924/10000 (99.24%)\n","\n","Epoch 7: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.003386575961485505 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0327, Accuracy: 9896/10000 (98.96%)\n","\n","Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n","Epoch 8: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.0019814581610262394 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0191, Accuracy: 9944/10000 (99.44%)\n","\n","Epoch 9: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.06423667818307877 batch_id=937: 100%|██████████| 938/938 [00:20<00:00, 44.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0206, Accuracy: 9934/10000 (99.34%)\n","\n","Epoch 10: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.07756365835666656 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0189, Accuracy: 9945/10000 (99.45%)\n","\n","Epoch 11: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.011073358356952667 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0194, Accuracy: 9939/10000 (99.39%)\n","\n","Epoch 12: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.08013952523469925 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 41.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0202, Accuracy: 9936/10000 (99.36%)\n","\n","Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch 13: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.005549655761569738 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0194, Accuracy: 9942/10000 (99.42%)\n","\n","Epoch 14: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.005162339191883802 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0190, Accuracy: 9944/10000 (99.44%)\n","\n","Epoch 00014: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch 15: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.0011867674766108394 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 43.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0193, Accuracy: 9938/10000 (99.38%)\n","\n","Epoch 16: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.08149804919958115 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 44.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0193, Accuracy: 9943/10000 (99.43%)\n","\n","Epoch 00016: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch 17: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.0007700475980527699 batch_id=937: 100%|██████████| 938/938 [00:21<00:00, 44.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0180, Accuracy: 9948/10000 (99.48%)\n","\n","Epoch 18: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.01887049525976181 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0178, Accuracy: 9944/10000 (99.44%)\n","\n","Epoch 19: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.006549663841724396 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0194, Accuracy: 9943/10000 (99.43%)\n","\n","Epoch 20: \n"]},{"output_type":"stream","name":"stderr","text":["Train set: Average loss=0.02715657837688923 batch_id=937: 100%|██████████| 938/938 [00:22<00:00, 42.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0177, Accuracy: 9948/10000 (99.48%)\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CB9IqymA745W","executionInfo":{"status":"ok","timestamp":1685856821456,"user_tz":-330,"elapsed":30,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"}}},"execution_count":8,"outputs":[]}]}